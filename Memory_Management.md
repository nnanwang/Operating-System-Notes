# Memory Management
Memory Sharing: "Space-sliced"<br>
Goals: Utilization, latency

#### Responsibilties
- **Memory Allocation** <br>
 responsible for allocating memory to processes
- **Address Mapping, necessary** <br>
  1) to run same code in different physical memory in different processes 
  2) to support process address space abstraction
  3) Memmory Management Unit (MMU): responsible for mapping logical addresses generated by CPU instructions to physical addresses seen by memory controller
  
#### MMU (Memory Management Unit)
- **MMU** usually on the same chip as the CPU
- **Translation** is tranparent to user/program
<img width="463" alt="image" src="https://user-images.githubusercontent.com/74788199/228639341-058182d9-5c09-4a48-993a-a9cdd137457f.png">

## Address Mapping
### Logical(vitual) Addresses: An Abstraction of Memory
- memory refrences in assembly language instructions <br>*(e.g.,* BR X, LOAD R2, Y *)*
- starts at 0, contiguous
- reality: must be mapped to physical address (address mapping)
<img width="864" alt="image" src="https://user-images.githubusercontent.com/74788199/235324214-b18171d8-4cc2-42c2-bd8e-db295f6d4464.png">

### Advantages
#### 1. Efficient Allocation of Memory
- Processes allocate and free memory as they run
- Need to find a way to make "room" for P1 to grow if P2 is right next to it

#### 2. Virtualization
- Allow a process to act as if has all the physical memory to itself 
- Allow all processes together to act if memory is much larger than reality

#### 3. Efficient use of Resources
- Don't waste memory
- Keep it all working

## Generating Logical Address
Generate at:
1. **Compile-time** - relative addressing resoled here (*e.g.,* X, Y)
2. **Link, load-time** - addresses dependent on external modules resolved here
3. **Execution-time** - addresses generated by dynamic loading/linking resolved here
![image](https://user-images.githubusercontent.com/74788199/235332973-f88f3ab8-ca76-4407-a524-b496f22038c3.png)

#### Logical address space: defined by base and limit registers
CPU: every physicaal memory access request must be between base and limit for that user <br>
![image](https://user-images.githubusercontent.com/74788199/235375342-257b7cad-63c5-4f8f-84e1-c3929dcc72e8.png)<br>
![image](https://user-images.githubusercontent.com/74788199/235375471-893afe67-2e6d-48e5-882b-ba0a24200266.png)

## Address Mapping
### Generating Physical Addresses
- addresses used in MAR (memory address register)
- generated at runtime (execution time) by memmory management unit (MMU)

![image](https://user-images.githubusercontent.com/74788199/235375747-7437fade-28a9-4af2-b8cd-f3d28e870dd7.png)

## Memory Allocation 
**Goals:**
- **High Utilization of Memory** <br> Ensure as much memmory used as possible (minimize waste)
- **High Concurrency** <br> Support as many processes as possibly needed
- **High performance** <br> Minimize performance impact

### Allocation Strategies
<img width="463" alt="image" src=https://user-images.githubusercontent.com/74788199/235376219-e1b0e8ec-8e6b-4606-bf2d-06bcdaf7e09b.png> <img width="463" alt="image" src=https://user-images.githubusercontent.com/74788199/235376244-c042f039-fcf1-4c57-b541-b0198969afc9.png>

## 1. Contiguos Allocation
| Advantages | Disadvantages |
|------------|---------------|
|- Easy implementation<br> - Easy to conceptualize | Poor memmory utilization |

#### Two Flavor: 
#### 1. Fixed Partition allocation (parking lot)
1. **Idea:** <br> devide memory a priori into fixed partitions (can vary in size) <br>
2. **Allocation Policy:** <br> process P arrives needing k units of space: *choose partition (Ri) that is smallest but >= k (best fit)<br>
3. **Utilization Issue:** <br> internal fragmentation: parts of allocated partition unused <br>
4. **Implementation:** <br> requires limit and relocation registers <br> ![image](https://user-images.githubusercontent.com/74788199/235376828-ddfcb4eb-320f-46a7-a1eb-e1bdbbdb341b.png) <br>
5. **In practice:** used in early batch systems <br> 
   1. knew memory needs of processes in advance
   2. memory needs didn't change much over process lifetime

#### 2. Variable Partition allocation *(side street parking)*
1. **Idea:** <br> Allocate memory chunks as needed *(analogous to side street parking)*  <br> ![image](https://user-images.githubusercontent.com/74788199/235377151-258696e4-e900-4b6f-9134-42415c7fcff5.png) <br> at any time, have a set of "holes" from which memory can be assigned <br> ![image](https://user-images.githubusercontent.com/74788199/235382997-ba5a0961-bef3-464c-9915-ad2c72078a48.png)

2. **Allocation Policy:** process P arrives needing k units of memory <br> ![image](https://user-images.githubusercontent.com/74788199/235383072-5996d6a6-49a1-4971-8aa1-e0b5eb1eaa61.png) <br> 
   a. **Best-fit: choose hole that is mallest but >= k** (B) <br> +: reserves big holes for big processes <br> -: creates small leftover holes ("external fragmentation") & must search the list <br> ![image](https://user-images.githubusercontent.com/74788199/235383225-91e229d4-3f09-4c9e-b872-c1f3eebea2de.png)
   b. **worst-fit: choose largest hole** (D) <br> +: creates larger leftover holes <br> -: many of the holes unusable & must search the list
   c. **First-fit: choose first hole with size >= k** (A) <br> +: no need to search list
   d. **Next-fit: choose next hole with size >= k** <br> +: easy to implement (does not search from the begging -> faster than first-fit)
|   External   |   Internal  |
|--------------|-------------|
|total memory exsits to satisfy request, but not contiguous| allocated memory may be > requested memory. Extra memory not used|

## 2. Non-Contiguous Allocation
Idea: Logical address space is partitioned, wach partition mapping to a contiguous chunk of memory <br>
![image](https://user-images.githubusercontent.com/74788199/235384206-cd457e1a-27a8-441d-b083-95cf1f446423.png)
| Advantages | Disadvantages |
|------------|---------------|
| Better memory utilization | more complex implementation |

### There are 3 Schemes:
### 1. Paging: 
all chunks the same size (i.e.: chunks are physically determined)
#### Basic Idea
- divide physical memory into fixed-size blocks (frames) (typical size: 512 bytes to 8KB (some power of 2))
- devide locgical memory into same-sized blocks (pages)
- within a page, memory contiguous but pages need not be contiguous or in order <br>![image](https://user-images.githubusercontent.com/74788199/235384706-e7aff02b-6b78-4259-b4dc-25fe98f5e66e.png)

#### Address Translation
Logical address = (p, d) <br>
- **p:** page number
- **d:** page offset: added to base address to find location within page/frame
![image](https://user-images.githubusercontent.com/74788199/235384941-c40d393c-b45d-446b-aab6-582bf1fb31a3.png)
An example: <br>
![image](https://user-images.githubusercontent.com/74788199/235386521-44bb9cd4-24d1-4d99-8f26-dc1a0bfd0282.png)

#### Page Table Implementation
Every Process' Page Table:<br>
- kept in main memory
- location kept in process (special status) registers: <br>
  a. **Page-table base register (PTBR):** location of page table for process
  b. **Page-table limit register (PTLR):** size of process page table
![image](https://user-images.githubusercontent.com/74788199/235388385-274eb599-abce-477a-8866-ce98ed071796.png)
![image](https://user-images.githubusercontent.com/74788199/235388397-38b0ae98-92e4-4536-9834-360f8363cbca.png)

#### Improving Memory Access
- Two Memory-Access Problem Sovled Using Associative Memory (Translation Look-Aside Buffers (TLB's)) <br> **TLB** = fast-lookup hardware cache containing parts of process page tables  <br>![image](https://user-images.githubusercontent.com/74788199/235388535-2c5807e1-7d99-444f-bf95-018ef623d21b.png)
- When doing page table lookup:
  1. First look in cache TLB
  2. If not in cache, look in memory page table
 Cache is faster than memory

![image](https://user-images.githubusercontent.com/74788199/235388710-1cf7f346-30a7-40be-83fa-4a51c9571b41.png)

#### Effective Access Time (EAT)
Analyzing the effecttiveness of TLB
- **Assume:** <br>
  - associative lookup in TLB takes ε time units
  - memory cycle time = 1 microsecond
- **Suppose:**
  - "hit radio" is α (hit radio = TLB hits / (TLB hits + misses)
- **Then:**
  - Effective Access Time (EAT) is: <br> 
    - EAT = ((1 + ε) α) + ((2 + ε)(1 - α)) <br>
          = α + εα + 2 - 2α + ε – εα <br>
          = 2 + ε - α
         
- **EAT = 2 + ε - α** - Effectiveness of TLB depends on high hit ratio!

### 2. Segmentation:
chunks are variably sized (logically determined)

### 3. Paged Segmentation:
hybrid of 1 and 2




4. 





